{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_nanospace2025 import GaussianProcess, RadialBasis, Noise, Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with GPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Bayesian optimization (BO) we wish to optimize some, possibly blackbox, function that is \n",
    "typically quite expensive to evaluate such as expensive calculations, such as DFT, or experiments. \n",
    "\n",
    "Formally, we say that we are looking for \n",
    "\n",
    "$$\n",
    "x_{\\mathrm{opt}} = \\mathrm{argmax}_{x \\in X} f(x)\n",
    "$$\n",
    "\n",
    "Wikipedia describes Bayesian optimization like so; \n",
    "> \"Since the objective function is unknown, the Bayesian strategy is to treat it as a random function and place a prior over it. The prior captures beliefs about the behavior of the function. After gathering the function evaluations, which are treated as data, the prior is updated to form the **posterior** distribution over the objective function. The posterior distribution, in turn, is used to construct an **acquisition function** that determines the next query point\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
